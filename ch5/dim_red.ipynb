{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_wine = pd.read_csv(\n",
    "    'data/wine.data',\n",
    "    header=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = df_wine.iloc[:, 1:].values, df_wine.iloc[:, 0].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=0, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the features\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_train_std = sc.fit_transform(X_train)\n",
    "X_test_std = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eigenvalues: \n",
      "[4.84274532 2.41602459 1.54845825 0.96120438 0.84166161 0.6620634\n",
      " 0.51828472 0.34650377 0.3131368  0.10754642 0.21357215 0.15362835\n",
      " 0.1808613 ]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "cov_mat = np.cov(X_train_std.T)\n",
    "eigen_vals, eigen_vecs = np.linalg.eig(cov_mat)\n",
    "print('Eigenvalues: ')\n",
    "print(eigen_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.3695146859960762,\n",
       " 0.1843492705988419,\n",
       " 0.11815159094596996,\n",
       " 0.07334251763785454,\n",
       " 0.06422107821731679,\n",
       " 0.050517244849076624,\n",
       " 0.03954653891241442,\n",
       " 0.026439183169220053,\n",
       " 0.023893192591852914,\n",
       " 0.016296137737251023,\n",
       " 0.013800211221948423,\n",
       " 0.01172226244308596,\n",
       " 0.00820608567909137]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exlained variance\n",
    "tot = sum(eigen_vals)\n",
    "var_exp = [(i / tot) for i in sorted(eigen_vals, reverse=True)]\n",
    "var_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.36951469, 0.55386396, 0.67201555, 0.74535807, 0.80957914,\n",
       "       0.86009639, 0.89964293, 0.92608211, 0.9499753 , 0.96627144,\n",
       "       0.98007165, 0.99179391, 1.        ])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cum_var_exp = np.cumsum(var_exp)\n",
    "cum_var_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the projection matrix W \n",
    "\n",
    "# First we make a list of (eigenvalue, eigenvector) pairs\n",
    "eigen_pairs = [(np.abs(eigen_vals[i]), eigen_vecs[:, i])\n",
    "                for i in range(len(eigen_vals))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the pairs from high to low\n",
    "eigen_pairs.sort(key=lambda k: -k[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.13724218,  0.24724326, -0.02545159,  0.20694508, -0.15436582,\n",
       "       -0.39376952, -0.41735106,  0.30572896, -0.30668347,  0.07554066,\n",
       "       -0.32613263, -0.36861022, -0.29669651])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eigen_pairs[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.13724218],\n",
       "       [ 0.24724326],\n",
       "       [-0.02545159],\n",
       "       [ 0.20694508],\n",
       "       [-0.15436582],\n",
       "       [-0.39376952],\n",
       "       [-0.41735106],\n",
       "       [ 0.30572896],\n",
       "       [-0.30668347],\n",
       "       [ 0.07554066],\n",
       "       [-0.32613263],\n",
       "       [-0.36861022],\n",
       "       [-0.29669651]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eigen_pairs[0][1][:, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix W:\n",
      " [[-0.13724218  0.50303478]\n",
      " [ 0.24724326  0.16487119]\n",
      " [-0.02545159  0.24456476]\n",
      " [ 0.20694508 -0.11352904]\n",
      " [-0.15436582  0.28974518]\n",
      " [-0.39376952  0.05080104]\n",
      " [-0.41735106 -0.02287338]\n",
      " [ 0.30572896  0.09048885]\n",
      " [-0.30668347  0.00835233]\n",
      " [ 0.07554066  0.54977581]\n",
      " [-0.32613263 -0.20716433]\n",
      " [-0.36861022 -0.24902536]\n",
      " [-0.29669651  0.38022942]]\n"
     ]
    }
   ],
   "source": [
    "# Choose top 2 eigenpairs\n",
    "w = np.hstack((eigen_pairs[0][1][:, np.newaxis],\n",
    "               eigen_pairs[1][1][:, np.newaxis]))\n",
    "\n",
    "print('Matrix W:\\n', w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.38299011, 0.45458499])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transform 13-dim example to 2-dim\n",
    "X_train_std[0].dot(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform entire training dataset\n",
    "X_train_pca = X_train_std.dot(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(multi_class=&#x27;ovr&#x27;, random_state=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(multi_class=&#x27;ovr&#x27;, random_state=1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(multi_class='ovr', random_state=1)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using sklearns built in PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "lr = LogisticRegression(multi_class='ovr', random_state=1, solver='lbfgs')\n",
    "\n",
    "# Dimensionality reduction\n",
    "X_train_pca = pca.fit_transform(X_train_std)\n",
    "X_test_pca = pca.transform(X_test_std)\n",
    "\n",
    "# Fitting the logistic regression model on the reduced dataset:\n",
    "lr.fit(X_train_pca, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9259259259259259"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred = lr.predict(X_test_pca)\n",
    "accuracy_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.36951469, 0.18434927, 0.11815159, 0.07334252, 0.06422108,\n",
       "       0.05051724, 0.03954654, 0.02643918, 0.02389319, 0.01629614,\n",
       "       0.01380021, 0.01172226, 0.00820609])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show explained variance ratio\n",
    "pca = PCA(n_components=None)\n",
    "X_train_pca = pca.fit_transform(X_train_std)\n",
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accessing feature contributions\n",
    "loadings = eigen_vecs * np.sqrt(eigen_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.3020184 ,  0.54408942, -0.05600938,  0.45540829, -0.33970111,\n",
       "       -0.8665386 , -0.9184327 ,  0.67279444, -0.67489496,  0.16623657,\n",
       "       -0.71769524, -0.81117245, -0.65291742])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loadings[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn_loadings = pca.components_.T * np.sqrt(pca.explained_variance_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.3020184 ,  0.54408942, -0.05600938,  0.45540829, -0.33970111,\n",
       "       -0.8665386 , -0.9184327 ,  0.67279444, -0.67489496,  0.16623657,\n",
       "       -0.71769524, -0.81117245, -0.65291742])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn_loadings[:, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supervised data compression via linear discriminant analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MV 1: [ 0.9066 -0.3497  0.3201 -0.7189  0.5056  0.8807  0.9589 -0.5516  0.5416\n",
      "  0.2338  0.5897  0.6563  1.2075]\n",
      "\n",
      "MV 2: [-0.8749 -0.2848 -0.3735  0.3157 -0.3848 -0.0433  0.0635 -0.0946  0.0703\n",
      " -0.8286  0.3144  0.3608 -0.7253]\n",
      "\n",
      "MV 3: [ 0.1992  0.866   0.1682  0.4148 -0.0451 -1.0286 -1.2876  0.8287 -0.7795\n",
      "  0.9649 -1.209  -1.3622 -0.4013]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Goal of LDA is to find the feature subspace that optimizes class seperability\n",
    "\n",
    "# First compute the mean vectors\n",
    "np.set_printoptions(precision=4)\n",
    "mean_vecs = []\n",
    "for label in range(1, 4):\n",
    "    mean_vecs.append(np.mean(\n",
    "        X_train_std[y_train == label], axis=0 # row-wise mean\n",
    "    ))\n",
    "    print(f'MV {label}: {mean_vecs[label-1]}\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 13  # Number of features\n",
    "S_W = np.zeros((d, d))\n",
    "\n",
    "for label, mv in zip(range(1, 4), mean_vecs):\n",
    "    class_scatter = np.zeros((d, d))\n",
    "    for row in X_train_std[y_train == label]:\n",
    "        row, mv = row.reshape(d, 1), mv.reshape(d, 1)\n",
    "        class_scatter += (row - mv).dot((row - mv).T)\n",
    "    S_W += class_scatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Within-class scatter matrix:  13x13\n"
     ]
    }
   ],
   "source": [
    "print('Within-class scatter matrix: ', f'{S_W.shape[0]}x{S_W.shape[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([41, 50, 33])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# But the above only holds when the classes are uniformly distirbuted which is NOT the case in our dataset:\n",
    "np.bincount(y_train)[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Within-class scatter matrix:  13x13\n"
     ]
    }
   ],
   "source": [
    "# So we need to scale it which turns out is equivalent to computing the covariance matrix (see book)\n",
    "d = 13  # Number of features\n",
    "S_W = np.zeros((d, d))\n",
    "\n",
    "for label, mv in zip(range(1, 4), mean_vecs):\n",
    "    class_scatter = np.cov(X_train_std[y_train == label].T)\n",
    "    S_W += class_scatter\n",
    "\n",
    "print('Within-class scatter matrix: ', f'{S_W.shape[0]}x{S_W.shape[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_std[y_train == 1, :].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the between class scatter matrix\n",
    "m= np.mean(X_train_std, axis=0)\n",
    "m.reshape(d, 1)\n",
    "\n",
    "d = 13\n",
    "S_B = np.zeros((d, d))\n",
    "for i, mv in enumerate(mean_vecs):\n",
    "    label = i + 1\n",
    "    n = X_train_std[y_train == label].shape[0]\n",
    "    mv = mv.reshape(d, 1)  # make into column vector\n",
    "    S_B += n * (mv - m).dot((mv - m).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Between-class scatter matrix:  13x13\n"
     ]
    }
   ],
   "source": [
    "print('Between-class scatter matrix: ', f'{S_B.shape[0]}x{S_B.shape[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigen_vals, eigen_vecs =\\\n",
    "    np.linalg.eig(np.linalg.inv(S_W).dot(S_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the eigenvalues\n",
    "eigen_pairs = [(np.abs(eigen_vals[i]), eigen_vecs[:, i]) for i in range(len(eigen_vals))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eigenvalues in descending order:\n",
      "4545.031515777923\n",
      "2245.8997884673204\n",
      "9.567859712868437e-13\n",
      "3.913813121771452e-13\n",
      "3.913813121771452e-13\n",
      "2.5264326998553025e-13\n",
      "1.5061811252533795e-13\n",
      "1.5061811252533795e-13\n",
      "1.0776570905878178e-13\n",
      "8.831441708994457e-14\n",
      "8.831441708994457e-14\n",
      "2.7614698410823634e-14\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "eigen_pairs.sort(key=lambda x: -x[0])\n",
    "print('Eigenvalues in descending order:')\n",
    "for eigen_val in eigen_pairs:\n",
    "    print(eigen_val[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix W:\n",
      " [[-0.1481 -0.4092]\n",
      " [ 0.0908 -0.1577]\n",
      " [-0.0168 -0.3537]\n",
      " [ 0.1484  0.3223]\n",
      " [-0.0163 -0.0817]\n",
      " [ 0.1913  0.0842]\n",
      " [-0.7338  0.2823]\n",
      " [-0.075  -0.0102]\n",
      " [ 0.0018  0.0907]\n",
      " [ 0.294  -0.2152]\n",
      " [-0.0328  0.2747]\n",
      " [-0.3547 -0.0124]\n",
      " [-0.3915 -0.5958]]\n"
     ]
    }
   ],
   "source": [
    "# Create transformation matrix\n",
    "\n",
    "w = np.hstack((eigen_pairs[0][1][:, np.newaxis].real,\n",
    "               eigen_pairs[1][1][:, np.newaxis].real))\n",
    "\n",
    "print('Matrix W:\\n', w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_lda = X_train_std.dot(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(124, 2)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_lda.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 1, 1, 1, 3, 2, 2, 3, 2, 2, 2, 1, 2, 3, 1, 3, 2, 1, 3, 3, 2, 1,\n",
       "       2, 2, 2, 2, 3, 1, 2, 2, 1, 1, 3, 1, 2, 1, 1, 2, 3, 3, 1, 3, 3, 3,\n",
       "       1, 2, 3, 3, 2, 3, 2, 2, 2, 1, 2, 2, 3, 3, 2, 1, 1, 2, 3, 3, 2, 1,\n",
       "       2, 2, 2, 1, 1, 1, 1, 1, 3, 1, 2, 3, 2, 2, 3, 1, 2, 1, 2, 2, 3, 2,\n",
       "       1, 1, 1, 3, 2, 1, 1, 2, 2, 3, 3, 2, 1, 1, 2, 2, 3, 1, 3, 1, 2, 2,\n",
       "       2, 2, 1, 3, 1, 1, 1, 1, 2, 2, 3, 3, 2, 2])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using sklearn\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "lda = LDA(n_components=2)\n",
    "X_train_lda = lda.fit_transform(X_train_std, y_train)\n",
    "\n",
    "lr = LogisticRegression(multi_class='ovr', random_state=1, solver='lbfgs')\n",
    "lr = lr.fit(X_train_lda, y_train)\n",
    "y_pred = lr.predict(X_train_lda)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_pred, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nonlinear Dim Red and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhYAAACXCAYAAABJNBKHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/P9b71AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAN+klEQVR4nO3db2iV5R/H8e/ZbGdW+6NM9s+VDLKl4KrZhpUgNBijKCJs2B7YjP6oj5oRCNmEiBFkBLH0QegICmdP6ontQYcKdJOFPiuETRYeXds065yj6Qbb9Xsgmy23/bwuv+f+s/v9ggN13HfXtft8vPfh3pl3zBhjBAAAQEGO3xsAAABLB8UCAACooVgAAAA1FAsAAKCGYgEAANRQLAAAgBqKBQAAULPMy8Wmp6dlZGRECgoKJBaLebk0HBhjJJPJSEVFheTk6HVQchAu2cgBGQgXzgWwyYCnxWJkZESqqqq8XBIKksmkrF69Wu3zkYNw0swBGQgnzgW4kwx4WiwKCgpE5ObGCgsLs77ewMCA9cyuXbuc1nr++eetZ959912ntfLz853mbKXTaamqqpp93bR4nQMXr7zyitPcpUuXrGc++ugjp7Uef/xxpzlb2chBGDIwODjoNNfY2Gg989RTTzmt9fXXXzvN2Voq5wKX47Vz506ntR566CHrmRMnTjit5cX3BJsMeFosZi51FRYWehKi++67z3omNzfXaa14PG4943oMvCoWM7QvUXqdAxf33HOP09yyZfZ/pe6//36ntbw+dpo5CEMGXF8Xl+PkmrcwZ+Dfn8+rHCxfvjzra8xw+V4Shu8Jd5IBpx+WdXV1yZo1ayQ/P18aGhqcrgwg3MgARMgByABuZ10senp6pL29XTo6OuTMmTNSW1srTU1NMj4+no39IYDIAETIAcgA5mddLD755BN5/fXXpa2tTdatWyeHDh2Se++9Vw4fPpyN/SGAyABEyAHIAOZnVSwmJyfl9OnTc96clJOTI42NjdLf33/bx09MTEg6nZ7zQLjZZkCEHCxFnAvAuQALsSoWly9flqmpKSktLZ3zfGlpqYyOjt728Z2dnVJUVDT74NeKws82AyLkYCniXADOBVhIVv/lzb1790oqlZp9JJPJbC6HgCIHIAMQIQdRYfW7cSUlJZKbmytjY2Nznh8bG5OysrLbPj4ejzv9GiaCyzYDIuRgKeJcAM4FWIjVFYu8vDypq6uTRCIx+9z09LQkEgnZtGmT+uYQPGQAIuQAZAALs/7XfNrb22X79u2yceNGqa+vl08//VSuXbsmbW1t2dgfAogMQIQcgAxgftbFoqWlRS5duiTvv/++jI6OyqOPPiq9vb23vYEHSxcZgAg5ABnA/GLGGOPVYul0WoqKiiSVSnnyz7c+8sgj1jNnz551Wuutt96ynjl06JDTWn19fdYzLpcms/V6eZ0DFzt27HCaO3LkiPXMBx984LTWe++95zRnKxuvl9cZuHjxovWM6822VqxYYT2zcuVKp7WGhoac5mwF7Vxw4MABp/W++OIL6xnXtZ599lnrmV9//dVprXXr1jnN2bB5rbL6WyEAACBaKBYAAEANxQIAAKihWAAAADUUCwAAoIZiAQAA1FAsAACAGooFAABQQ7EAAABqKBYAAEANxQIAAKihWAAAADUUCwAAoMb6tul+SCaTTnMudyq9cuWK01oudzR0Xcuru5suFS53tvz222/1N7KAKL82Xvnuu++sZ5588kmntVpbW61ndu/e7bRWVLnefdjlOD/22GNOa9XU1FjPeHGXUi9wxQIAAKihWAAAADUUCwAAoIZiAQAA1FAsAACAGooFAABQQ7EAAABqKBYAAEANxQIAAKihWAAAADUUCwAAoIZiAQAA1ITiJmSZTMZpbsuWLdYzLjcTc1VfX+/ZWktBT0+P09zOnTutZ/766y+ntVzU1dV5tlZUudy06uGHH3Zaa+vWrdYzbW1tTmtFlet52uXvtcvNLEVEXn75ZeuZGzduOK2Vn5/vNJctXLEAAABqKBYAAEANxQIAAKihWAAAADUUCwAAoIZiAQAA1FAsAACAGooFAABQQ7EAAABqKBYAAEANxQIAAKihWAAAADUUCwAAoCYUdzdNpVJOc88995zyTnRduXLFaW7lypXKOwmHlpYWp7kXXnjBemb58uVOa7m4du2a01xxcbHuRkLA9e6Phw8ftp756quvnNZy8fnnn3u2VpS53BX1+vXrTms1Nzd7MiMi8v3331vPZPOOqFyxAAAAaigWAABADcUCAACooVgAAAA1FAsAAKCGYgEAANRQLAAAgBqKBQAAUEOxAAAAaigWAABADcUCAACooVgAAAA1obgJWVFRkdPcwMCA8k4W5nJzpL6+Pqe1Xn31Vac5BNPZs2ed5iorK5V3Enwff/yx09y+ffuUd7KwX375xXommzeEwt1xfW1cbgz29ttvO63V1dVlPbNnzx6nte4EVywAAIAaigUAAFBDsQAAAGqsisX+/fslFovNedTU1GRrbwggMgARcgAygIVZv3lz/fr18sMPP9z6BMtC8f5PKCIDECEHIAOYn3UKli1bJmVlZdnYC0KCDECEHIAMYH7W77EYHByUiooKqa6ultbWVjl//vyCHzsxMSHpdHrOA+FnkwERcrBUcS4A5wLMx6pYNDQ0SHd3t/T29srBgwdleHhYNm/eLJlMZt6P7+zslKKiotlHVVWVyqbhH9sMiJCDpYhzATgXYCFWxaK5uVm2bt0qGzZskKamJjl+/Lj8/fffcuzYsXk/fu/evZJKpWYfyWRSZdPwj20GRMjBUsS5AJwLsJC7eqdNcXGxrF27VoaGhub983g8LvF4/G6WQMD9vwyIkIMo4FwAzgWYcVf/jsXVq1fl3LlzUl5errUfhAwZgAg5ABnALVbF4p133pGff/5Zfv/9d+nr65MXX3xRcnNzZdu2bdnaHwKGDECEHIAMYGFWPwq5cOGCbNu2Tf78809ZtWqVPP3003Lq1ClZtWpVtvaHgCEDECEHIANYmFWxOHr0aLb2sSjXS2uJRMJ6pr+/32mtL7/80mnOxfbt2z1b67/8ygCCxa8ctLW1Oc253GnS9e7DTzzxhPWM69e1a9cu65mNGzc6rfVfYTwXHDhwwHqmubnZaa1UKmU988033zit9eabbzrNZQv3CgEAAGooFgAAQA3FAgAAqKFYAAAANRQLAACghmIBAADUUCwAAIAaigUAAFBDsQAAAGooFgAAQA3FAgAAqKFYAAAANVY3IfPLihUrnOZcbgy2Y8cOp7W2bNliPfPjjz86rQU7+fn51jOuN4U6cuSI9czx48ed1nrmmWec5sKssrLSae7kyZPWMxcvXnRaa9++fdYzLrkREamurrae0boJWRiVlJRYz7z00ktZ2Mn8XG8m9uGHHyrv5O5wxQIAAKihWAAAADUUCwAAoIZiAQAA1FAsAACAGooFAABQQ7EAAABqKBYAAEANxQIAAKihWAAAADUUCwAAoIZiAQAA1Hh6EzJjjIiIpNNpT9b7559/rGempqac1pqcnLSe8eo4uJrZ38zrpsXrHLhweT1dTUxMOM15dfyykYMwZCCTyTjNeZmdGzduWM+4HPOlci64fv269Yzr9wQXQT4X2GQgZrSTsogLFy5IVVWVV8tBSTKZlNWrV6t9PnIQTpo5IAPhxLkAd5IBT4vF9PS0jIyMSEFBgcRisTl/lk6npaqqSpLJpBQWFnq1pcAKwvEwxkgmk5GKigrJydH7qRk5uDNBORbZyAEZuDNBORZenwuC8nUHRRCOh00GPP1RSE5Ozv9tOoWFhQTpX/w+HkVFReqfkxzYCcKx0M4BGbAThGPhx7kgCF93kPh9PO40A7x5EwAAqKFYAAAANYEpFvF4XDo6OiQej/u9lUCI6vGI6tc9n6gei6h+3fOJ6rGI6te9kLAdD0/fvAkAAJa2wFyxAAAA4UexAAAAaigWAABADcUCAACooVgAAAA1gSkWXV1dsmbNGsnPz5eGhgYZGBjwe0ue279/v8RisTmPmpoav7flGTJwU5RzQAZuinIGRMiBSLgzEIhi0dPTI+3t7dLR0SFnzpyR2tpaaWpqkvHxcb+35rn169fLH3/8Mfs4ceKE31vyBBmYK4o5IANzRTEDIuTg30KbARMA9fX1Zvfu3bP/PzU1ZSoqKkxnZ6ePu/JeR0eHqa2t9XsbviADt0Q1B2TglqhmwBhyMCPMGfD9isXk5KScPn1aGhsbZ5/LycmRxsZG6e/v93Fn/hgcHJSKigqprq6W1tZWOX/+vN9byjoycLuo5YAM3C5qGRAhB/8V1gz4XiwuX74sU1NTUlpaOuf50tJSGR0d9WlX/mhoaJDu7m7p7e2VgwcPyvDwsGzevFkymYzfW8sqMjBXFHNABuaKYgZEyMG/hTkDnt42HYtrbm6e/e8NGzZIQ0ODPPjgg3Ls2DF57bXXfNwZvEQOQAYQ5gz4fsWipKREcnNzZWxsbM7zY2NjUlZW5tOugqG4uFjWrl0rQ0NDfm8lq8jA4qKQAzKwuChkQIQcLCZMGfC9WOTl5UldXZ0kEonZ56anpyWRSMimTZt83Jn/rl69KufOnZPy8nK/t5JVZGBxUcgBGVhcFDIgQg4WE6oM+P3uUWOMOXr0qInH46a7u9v89ttv5o033jDFxcVmdHTU7615as+ePeann34yw8PD5uTJk6axsdGUlJSY8fFxv7eWdWTglqjmgAzcEtUMGEMOZoQ5A4EoFsYY89lnn5kHHnjA5OXlmfr6enPq1Cm/t+S5lpYWU15ebvLy8kxlZaVpaWkxQ0NDfm/LM2TgpijngAzcFOUMGEMOjAl3BmLGGOP3VRMAALA0+P4eCwAAsHRQLAAAgBqKBQAAUEOxAAAAaigWAABADcUCAACooVgAAAA1FAsAAKCGYgEAANRQLAAAgBqKBQAAUPM/pPEttHc+r5IAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# t-SNE\n",
    "from sklearn.datasets import load_digits\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "digits = load_digits()\n",
    "\n",
    "fig, ax = plt.subplots(1, 4)\n",
    "for i in range(4):\n",
    "    ax[i].imshow(digits.images[i], cmap='Greys')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797, 64)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_digits = digits.target\n",
    "X_digits = digits.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "tsne = TSNE(n_components=2, init='pca', random_state=123)\n",
    "X_digits_tsne = tsne.fit_transform(X_digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
